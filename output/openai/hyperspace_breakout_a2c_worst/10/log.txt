Logging to /home/ygx/src/vel/output/openai/hyperspace_breakout_a2c_worst/10
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 2        |
| PMM:episode_rewards | 0.93     |
| advantage_norm      | 4.44     |
| episode_length      | 163      |
| epoch_idx           | 1        |
| explained_variance  | -5.74    |
| fps                 | 530      |
| frames              | 8000     |
| grad_norm           | 28.1     |
| policy_entropy      | 1.34     |
| policy_loss         | 0.0757   |
| value_loss          | 1.06     |
----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 3        |
| PMM:episode_rewards | 1.1      |
| advantage_norm      | 0.756    |
| episode_length      | 170      |
| epoch_idx           | 2        |
| explained_variance  | -4.36    |
| fps                 | 337      |
| frames              | 16000    |
| grad_norm           | 0.0981   |
| policy_entropy      | 1.38     |
| policy_loss         | 0.00127  |
| value_loss          | 0.006    |
----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 4        |
| PMM:episode_rewards | 1.37     |
| advantage_norm      | 0.676    |
| episode_length      | 180      |
| epoch_idx           | 3        |
| explained_variance  | -3.46    |
| fps                 | 381      |
| frames              | 24000    |
| grad_norm           | 0.0817   |
| policy_entropy      | 1.38     |
| policy_loss         | -0.00131 |
| value_loss          | 0.00535  |
----------------------------------
-----------------------------------
| P01:episode_rewards | 0         |
| P09:episode_rewards | 4.1       |
| PMM:episode_rewards | 1.39      |
| advantage_norm      | 0.735     |
| episode_length      | 182       |
| epoch_idx           | 4         |
| explained_variance  | -1.45     |
| fps                 | 398       |
| frames              | 32000     |
| grad_norm           | 0.0806    |
| policy_entropy      | 1.38      |
| policy_loss         | -0.000437 |
| value_loss          | 0.00551   |
-----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 4        |
| PMM:episode_rewards | 1.52     |
| advantage_norm      | 0.736    |
| episode_length      | 189      |
| epoch_idx           | 5        |
| explained_variance  | -1.25    |
| fps                 | 409      |
| frames              | 40000    |
| grad_norm           | 0.0731   |
| policy_entropy      | 1.38     |
| policy_loss         | 0.000446 |
| value_loss          | 0.00571  |
----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 4        |
| PMM:episode_rewards | 1.46     |
| advantage_norm      | 0.718    |
| episode_length      | 184      |
| epoch_idx           | 6        |
| explained_variance  | -1.34    |
| fps                 | 414      |
| frames              | 48000    |
| grad_norm           | 0.0621   |
| policy_entropy      | 1.38     |
| policy_loss         | 0.000483 |
| value_loss          | 0.00559  |
----------------------------------
-----------------------------------
| P01:episode_rewards | 0         |
| P09:episode_rewards | 3         |
| PMM:episode_rewards | 1.09      |
| advantage_norm      | 0.56      |
| episode_length      | 169       |
| epoch_idx           | 7         |
| explained_variance  | -3.07     |
| fps                 | 417       |
| frames              | 56000     |
| grad_norm           | 0.0516    |
| policy_entropy      | 1.38      |
| policy_loss         | -0.000234 |
| value_loss          | 0.00417   |
-----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 3        |
| PMM:episode_rewards | 0.92     |
| advantage_norm      | 0.564    |
| episode_length      | 165      |
| epoch_idx           | 8        |
| explained_variance  | -2.23    |
| fps                 | 419      |
| frames              | 64000    |
| grad_norm           | 0.0746   |
| policy_entropy      | 1.39     |
| policy_loss         | 0.00386  |
| value_loss          | 0.0046   |
----------------------------------
