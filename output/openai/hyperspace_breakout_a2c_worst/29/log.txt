Logging to /home/ygx/src/vel/output/openai/hyperspace_breakout_a2c_worst/29
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 3        |
| PMM:episode_rewards | 1.1      |
| advantage_norm      | 5.33     |
| episode_length      | 170      |
| epoch_idx           | 1        |
| explained_variance  | -1.2     |
| fps                 | 508      |
| frames              | 8000     |
| grad_norm           | 43.8     |
| policy_entropy      | 1.33     |
| policy_loss         | -0.0818  |
| value_loss          | 1.93     |
----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 3        |
| PMM:episode_rewards | 1.06     |
| advantage_norm      | 0.648    |
| episode_length      | 169      |
| epoch_idx           | 2        |
| explained_variance  | -4.12    |
| fps                 | 306      |
| frames              | 16000    |
| grad_norm           | 0.124    |
| policy_entropy      | 1.38     |
| policy_loss         | 0.000437 |
| value_loss          | 0.00496  |
----------------------------------
-----------------------------------
| P01:episode_rewards | 0         |
| P09:episode_rewards | 3         |
| PMM:episode_rewards | 1.16      |
| advantage_norm      | 0.631     |
| episode_length      | 174       |
| epoch_idx           | 3         |
| explained_variance  | -6.02     |
| fps                 | 343       |
| frames              | 24000     |
| grad_norm           | 0.0929    |
| policy_entropy      | 1.39      |
| policy_loss         | -0.000349 |
| value_loss          | 0.00499   |
-----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 3        |
| PMM:episode_rewards | 1.23     |
| advantage_norm      | 0.728    |
| episode_length      | 176      |
| epoch_idx           | 4        |
| explained_variance  | -2.54    |
| fps                 | 367      |
| frames              | 32000    |
| grad_norm           | 0.0986   |
| policy_entropy      | 1.39     |
| policy_loss         | 0.000827 |
| value_loss          | 0.00576  |
----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 3        |
| PMM:episode_rewards | 1.21     |
| advantage_norm      | 0.673    |
| episode_length      | 174      |
| epoch_idx           | 5        |
| explained_variance  | -2.01    |
| fps                 | 383      |
| frames              | 40000    |
| grad_norm           | 0.073    |
| policy_entropy      | 1.39     |
| policy_loss         | 0.000307 |
| value_loss          | 0.00515  |
----------------------------------
-----------------------------------
| P01:episode_rewards | 0         |
| P09:episode_rewards | 3         |
| PMM:episode_rewards | 1.31      |
| advantage_norm      | 0.735     |
| episode_length      | 178       |
| epoch_idx           | 6         |
| explained_variance  | -1.65     |
| fps                 | 395       |
| frames              | 48000     |
| grad_norm           | 0.0978    |
| policy_entropy      | 1.39      |
| policy_loss         | -0.000821 |
| value_loss          | 0.00579   |
-----------------------------------
-----------------------------------
| P01:episode_rewards | 0         |
| P09:episode_rewards | 4         |
| PMM:episode_rewards | 1.4       |
| advantage_norm      | 0.759     |
| episode_length      | 183       |
| epoch_idx           | 7         |
| explained_variance  | -1.23     |
| fps                 | 403       |
| frames              | 56000     |
| grad_norm           | 0.0671    |
| policy_entropy      | 1.39      |
| policy_loss         | -0.000203 |
| value_loss          | 0.00595   |
-----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 4        |
| PMM:episode_rewards | 1.29     |
| advantage_norm      | 0.641    |
| episode_length      | 180      |
| epoch_idx           | 8        |
| explained_variance  | -2.4     |
| fps                 | 408      |
| frames              | 64000    |
| grad_norm           | 0.0594   |
| policy_entropy      | 1.39     |
| policy_loss         | 0.000306 |
| value_loss          | 0.00496  |
----------------------------------
