Logging to /home/ygx/src/vel/output/openai/hyperspace_breakout_a2c_worst/19
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 3        |
| PMM:episode_rewards | 1.27     |
| advantage_norm      | 5.04     |
| episode_length      | 168      |
| epoch_idx           | 1        |
| explained_variance  | -3.41    |
| fps                 | 525      |
| frames              | 8000     |
| grad_norm           | 30.6     |
| policy_entropy      | 1.34     |
| policy_loss         | -0.0785  |
| value_loss          | 1.12     |
----------------------------------
-----------------------------------
| P01:episode_rewards | 0         |
| P09:episode_rewards | 3         |
| PMM:episode_rewards | 1.22      |
| advantage_norm      | 0.666     |
| episode_length      | 170       |
| epoch_idx           | 2         |
| explained_variance  | -3.54     |
| fps                 | 318       |
| frames              | 16000     |
| grad_norm           | 0.0898    |
| policy_entropy      | 1.39      |
| policy_loss         | -0.000485 |
| value_loss          | 0.00529   |
-----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 4        |
| PMM:episode_rewards | 1.3      |
| advantage_norm      | 0.739    |
| episode_length      | 179      |
| epoch_idx           | 3        |
| explained_variance  | -1.79    |
| fps                 | 359      |
| frames              | 24000    |
| grad_norm           | 0.0799   |
| policy_entropy      | 1.38     |
| policy_loss         | 0.000319 |
| value_loss          | 0.00571  |
----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 4        |
| PMM:episode_rewards | 1.53     |
| advantage_norm      | 0.757    |
| episode_length      | 187      |
| epoch_idx           | 4        |
| explained_variance  | -1.87    |
| fps                 | 386      |
| frames              | 32000    |
| grad_norm           | 0.0795   |
| policy_entropy      | 1.38     |
| policy_loss         | 4e-05    |
| value_loss          | 0.00612  |
----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 5        |
| PMM:episode_rewards | 1.82     |
| advantage_norm      | 0.847    |
| episode_length      | 197      |
| epoch_idx           | 5        |
| explained_variance  | -0.959   |
| fps                 | 401      |
| frames              | 40000    |
| grad_norm           | 0.0894   |
| policy_entropy      | 1.38     |
| policy_loss         | 0.000804 |
| value_loss          | 0.007    |
----------------------------------
-----------------------------------
| P01:episode_rewards | 0         |
| P09:episode_rewards | 4         |
| PMM:episode_rewards | 1.72      |
| advantage_norm      | 0.732     |
| episode_length      | 193       |
| epoch_idx           | 6         |
| explained_variance  | -3.53     |
| fps                 | 410       |
| frames              | 48000     |
| grad_norm           | 0.0763    |
| policy_entropy      | 1.39      |
| policy_loss         | -0.000709 |
| value_loss          | 0.0055    |
-----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 4        |
| PMM:episode_rewards | 1.61     |
| advantage_norm      | 0.801    |
| episode_length      | 189      |
| epoch_idx           | 7        |
| explained_variance  | -1.05    |
| fps                 | 417      |
| frames              | 56000    |
| grad_norm           | 0.0866   |
| policy_entropy      | 1.39     |
| policy_loss         | 0.000328 |
| value_loss          | 0.00643  |
----------------------------------
-----------------------------------
| P01:episode_rewards | 0         |
| P09:episode_rewards | 3.1       |
| PMM:episode_rewards | 1.45      |
| advantage_norm      | 0.648     |
| episode_length      | 185       |
| epoch_idx           | 8         |
| explained_variance  | -5.13     |
| fps                 | 421       |
| frames              | 64000     |
| grad_norm           | 0.0708    |
| policy_entropy      | 1.39      |
| policy_loss         | -0.000261 |
| value_loss          | 0.005     |
-----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 3        |
| PMM:episode_rewards | 1.4      |
| advantage_norm      | 0.8      |
| episode_length      | 184      |
| epoch_idx           | 9        |
| explained_variance  | -1.64    |
| fps                 | 426      |
| frames              | 72000    |
| grad_norm           | 0.0966   |
| policy_entropy      | 1.38     |
| policy_loss         | 0.000156 |
| value_loss          | 0.00615  |
----------------------------------
