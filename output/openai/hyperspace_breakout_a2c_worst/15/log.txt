Logging to /home/ygx/src/vel/output/openai/hyperspace_breakout_a2c_worst/15
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 3        |
| PMM:episode_rewards | 1.05     |
| advantage_norm      | 4.5      |
| episode_length      | 170      |
| epoch_idx           | 1        |
| explained_variance  | -2.79    |
| fps                 | 529      |
| frames              | 8000     |
| grad_norm           | 28       |
| policy_entropy      | 1.36     |
| policy_loss         | 0.153    |
| value_loss          | 0.995    |
----------------------------------
-----------------------------------
| P01:episode_rewards | 0         |
| P09:episode_rewards | 4         |
| PMM:episode_rewards | 1.3       |
| advantage_norm      | 0.806     |
| episode_length      | 180       |
| epoch_idx           | 2         |
| explained_variance  | -3.41     |
| fps                 | 315       |
| frames              | 16000     |
| grad_norm           | 0.147     |
| policy_entropy      | 1.38      |
| policy_loss         | -0.000608 |
| value_loss          | 0.00657   |
-----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 4        |
| PMM:episode_rewards | 1.44     |
| advantage_norm      | 0.743    |
| episode_length      | 186      |
| epoch_idx           | 3        |
| explained_variance  | -2.94    |
| fps                 | 359      |
| frames              | 24000    |
| grad_norm           | 0.103    |
| policy_entropy      | 1.39     |
| policy_loss         | 3.77e-06 |
| value_loss          | 0.00585  |
----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 4        |
| PMM:episode_rewards | 1.32     |
| advantage_norm      | 0.731    |
| episode_length      | 181      |
| epoch_idx           | 4        |
| explained_variance  | -3.48    |
| fps                 | 383      |
| frames              | 32000    |
| grad_norm           | 0.0974   |
| policy_entropy      | 1.38     |
| policy_loss         | 0.000697 |
| value_loss          | 0.00596  |
----------------------------------
-----------------------------------
| P01:episode_rewards | 0         |
| P09:episode_rewards | 3.1       |
| PMM:episode_rewards | 1.48      |
| advantage_norm      | 0.78      |
| episode_length      | 184       |
| epoch_idx           | 5         |
| explained_variance  | -1.73     |
| fps                 | 396       |
| frames              | 40000     |
| grad_norm           | 0.106     |
| policy_entropy      | 1.38      |
| policy_loss         | -0.000239 |
| value_loss          | 0.00626   |
-----------------------------------
-----------------------------------
| P01:episode_rewards | 0         |
| P09:episode_rewards | 4         |
| PMM:episode_rewards | 1.78      |
| advantage_norm      | 0.827     |
| episode_length      | 195       |
| epoch_idx           | 6         |
| explained_variance  | -1.42     |
| fps                 | 408       |
| frames              | 48000     |
| grad_norm           | 0.0973    |
| policy_entropy      | 1.38      |
| policy_loss         | -0.000211 |
| value_loss          | 0.00639   |
-----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 4        |
| PMM:episode_rewards | 1.6      |
| advantage_norm      | 0.705    |
| episode_length      | 188      |
| epoch_idx           | 7        |
| explained_variance  | -3.43    |
| fps                 | 414      |
| frames              | 56000    |
| grad_norm           | 0.0904   |
| policy_entropy      | 1.38     |
| policy_loss         | 0.000467 |
| value_loss          | 0.00537  |
----------------------------------
-----------------------------------
| P01:episode_rewards | 0         |
| P09:episode_rewards | 3         |
| PMM:episode_rewards | 1.26      |
| advantage_norm      | 0.668     |
| episode_length      | 176       |
| epoch_idx           | 8         |
| explained_variance  | -2.71     |
| fps                 | 418       |
| frames              | 64000     |
| grad_norm           | 0.0859    |
| policy_entropy      | 1.38      |
| policy_loss         | -0.000414 |
| value_loss          | 0.00512   |
-----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 3        |
| PMM:episode_rewards | 1.34     |
| advantage_norm      | 0.697    |
| episode_length      | 178      |
| epoch_idx           | 9        |
| explained_variance  | -3.48    |
| fps                 | 422      |
| frames              | 72000    |
| grad_norm           | 0.0855   |
| policy_entropy      | 1.38     |
| policy_loss         | 0.000143 |
| value_loss          | 0.0056   |
----------------------------------
