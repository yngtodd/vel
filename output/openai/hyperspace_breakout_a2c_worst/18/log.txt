Logging to /home/ygx/src/vel/output/openai/hyperspace_breakout_a2c_worst/18
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 3        |
| PMM:episode_rewards | 1.1      |
| advantage_norm      | 3.97     |
| episode_length      | 171      |
| epoch_idx           | 1        |
| explained_variance  | -7.27    |
| fps                 | 512      |
| frames              | 8000     |
| grad_norm           | 22.7     |
| policy_entropy      | 1.35     |
| policy_loss         | 0.0215   |
| value_loss          | 0.799    |
----------------------------------
-----------------------------------
| P01:episode_rewards | 0         |
| P09:episode_rewards | 3         |
| PMM:episode_rewards | 1.38      |
| advantage_norm      | 0.786     |
| episode_length      | 182       |
| epoch_idx           | 2         |
| explained_variance  | -2.41     |
| fps                 | 309       |
| frames              | 16000     |
| grad_norm           | 0.108     |
| policy_entropy      | 1.38      |
| policy_loss         | -0.000111 |
| value_loss          | 0.00655   |
-----------------------------------
-----------------------------------
| P01:episode_rewards | 0         |
| P09:episode_rewards | 3         |
| PMM:episode_rewards | 1.47      |
| advantage_norm      | 0.69      |
| episode_length      | 187       |
| epoch_idx           | 3         |
| explained_variance  | -4.4      |
| fps                 | 350       |
| frames              | 24000     |
| grad_norm           | 0.0863    |
| policy_entropy      | 1.39      |
| policy_loss         | -0.000291 |
| value_loss          | 0.00575   |
-----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 3        |
| PMM:episode_rewards | 1.28     |
| advantage_norm      | 0.6      |
| episode_length      | 178      |
| epoch_idx           | 4        |
| explained_variance  | -3.39    |
| fps                 | 372      |
| frames              | 32000    |
| grad_norm           | 0.0744   |
| policy_entropy      | 1.39     |
| policy_loss         | 0.000741 |
| value_loss          | 0.00458  |
----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 3        |
| PMM:episode_rewards | 1.18     |
| advantage_norm      | 0.731    |
| episode_length      | 174      |
| epoch_idx           | 5        |
| explained_variance  | -2.8     |
| fps                 | 389      |
| frames              | 40000    |
| grad_norm           | 0.0787   |
| policy_entropy      | 1.39     |
| policy_loss         | 0.000254 |
| value_loss          | 0.00573  |
----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 4        |
| PMM:episode_rewards | 1.33     |
| advantage_norm      | 0.82     |
| episode_length      | 183      |
| epoch_idx           | 6        |
| explained_variance  | -1.5     |
| fps                 | 400      |
| frames              | 48000    |
| grad_norm           | 0.0845   |
| policy_entropy      | 1.38     |
| policy_loss         | 0.000121 |
| value_loss          | 0.00655  |
----------------------------------
-----------------------------------
| P01:episode_rewards | 0         |
| P09:episode_rewards | 4         |
| PMM:episode_rewards | 1.49      |
| advantage_norm      | 0.612     |
| episode_length      | 190       |
| epoch_idx           | 7         |
| explained_variance  | -2.72     |
| fps                 | 407       |
| frames              | 56000     |
| grad_norm           | 0.0804    |
| policy_entropy      | 1.38      |
| policy_loss         | -0.000348 |
| value_loss          | 0.00449   |
-----------------------------------
----------------------------------
| P01:episode_rewards | 0        |
| P09:episode_rewards | 4        |
| PMM:episode_rewards | 1.31     |
| advantage_norm      | 0.738    |
| episode_length      | 180      |
| epoch_idx           | 8        |
| explained_variance  | -4.03    |
| fps                 | 412      |
| frames              | 64000    |
| grad_norm           | 0.0876   |
| policy_entropy      | 1.38     |
| policy_loss         | 0.000193 |
| value_loss          | 0.00561  |
----------------------------------
